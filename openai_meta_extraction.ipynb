{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt update\n",
    "%pip install -q -U python-dotenv\n",
    "%pip install -q -U pdf2image\n",
    "!sudo apt install --yes poppler-utils\n",
    "%pip install -q -U openai\n",
    "%pip install -q -U pytesseract\n",
    "!sudo apt install --yes tesseract-ocr\n",
    "%pip install -q -U Unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:45:41.689150Z",
     "iopub.status.busy": "2024-09-23T15:45:41.688679Z",
     "iopub.status.idle": "2024-09-23T15:45:42.294717Z",
     "shell.execute_reply": "2024-09-23T15:45:42.294222Z",
     "shell.execute_reply.started": "2024-09-23T15:45:41.689128Z"
    },
    "id": "dJMeuXkUMyDW"
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from enum import Enum\n",
    "from openai import OpenAI\n",
    "from pdf2image import convert_from_bytes, convert_from_path\n",
    "from PIL import Image\n",
    "from pydantic import BaseModel\n",
    "from tqdm import tqdm\n",
    "from typing import List, Literal, Optional, Union\n",
    "from unidecode import unidecode\n",
    "from urllib.parse import urlparse, urlunparse\n",
    "import json\n",
    "import os\n",
    "import pytesseract\n",
    "import re\n",
    "import requests\n",
    "import tempfile\n",
    "import unicodedata\n",
    "import urllib\n",
    "import base64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:45:43.547786Z",
     "iopub.status.busy": "2024-09-23T15:45:43.547072Z",
     "iopub.status.idle": "2024-09-23T15:45:43.553289Z",
     "shell.execute_reply": "2024-09-23T15:45:43.552905Z",
     "shell.execute_reply.started": "2024-09-23T15:45:43.547754Z"
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "WEIGHTS_AND_BIASES = os.environ[\"WEIGHTS_AND_BIASES\"]\n",
    "HF_TOKEN = os.environ[\"HF_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:45:44.192969Z",
     "iopub.status.busy": "2024-09-23T15:45:44.192434Z",
     "iopub.status.idle": "2024-09-23T15:45:44.195708Z",
     "shell.execute_reply": "2024-09-23T15:45:44.195199Z",
     "shell.execute_reply.started": "2024-09-23T15:45:44.192939Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = \"./documents\"\n",
    "PDF_PATH = os.path.join(DATASET_PATH, \"german_pdf_files\")\n",
    "IMAGE_PATH = os.path.join(DATASET_PATH, \"german_img_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:45:45.672504Z",
     "iopub.status.busy": "2024-09-23T15:45:45.671781Z",
     "iopub.status.idle": "2024-09-23T15:45:45.830257Z",
     "shell.execute_reply": "2024-09-23T15:45:45.829861Z",
     "shell.execute_reply.started": "2024-09-23T15:45:45.672477Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(PDF_PATH, \"mapping.json\"), \"r\", encoding=\"utf8\") as json_file:\n",
    "    mappings_pdf = json.load(json_file)\n",
    "    print(\"Current number of PDFs:\", len(mappings_pdf))\n",
    "\n",
    "\n",
    "with open(os.path.join(IMAGE_PATH, \"mapping.json\"), \"r\", encoding=\"utf8\") as json_file:\n",
    "    mappings_img = json.load(json_file)\n",
    "    print(\"Current number of images:\", len(mappings_img))\n",
    "\n",
    "with open(\n",
    "    os.path.join(DATASET_PATH, \"extraction.json\"), \"r\", encoding=\"utf8\"\n",
    ") as json_file:\n",
    "    extraction = json.load(json_file)\n",
    "    print(\"Current number of metadata extractions:\", len(extraction))\n",
    "\n",
    "with open(os.path.join(DATASET_PATH, \"transcripts.json\"), \"r\", encoding=\"utf8\") as json_file:\n",
    "    transcripts = json.load(json_file)\n",
    "    print(\"Current number of transcripts:\", len(transcripts))\n",
    "\n",
    "del mappings_img[\"https://www.geo-iburg.de/Bergaufsicht.pdf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrBUkLLsLVia"
   },
   "source": [
    "# Download Scraped PDF Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-23T14:33:02.225876Z",
     "iopub.status.idle": "2024-09-23T14:33:02.226028Z",
     "shell.execute_reply": "2024-09-23T14:33:02.225979Z",
     "shell.execute_reply.started": "2024-09-23T14:33:02.225979Z"
    },
    "id": "du-s1LaGLhDC"
   },
   "outputs": [],
   "source": [
    "!wget https://digitalcorpora.s3.amazonaws.com/corpora/files/CC-MAIN-2021-31-PDF-UNTRUNCATED/metadata/cc-provenance-20230303.csv.gz\n",
    "!gunzip cc-provenance-20230303.csv.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T14:33:06.630436Z",
     "iopub.status.busy": "2024-09-23T14:33:06.629539Z",
     "iopub.status.idle": "2024-09-23T14:34:01.637522Z",
     "shell.execute_reply": "2024-09-23T14:34:01.637142Z",
     "shell.execute_reply.started": "2024-09-23T14:33:06.630378Z"
    },
    "id": "KVeT_PkrLkJm"
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open(\"./cc-provenance-20230303.csv\") as csv_file:\n",
    "    for line in csv_file:\n",
    "        lines.append(line)\n",
    "header = lines[0]\n",
    "content = lines[1:]\n",
    "\n",
    "content = [line.split(\",\")[2] for line in content]\n",
    "\n",
    "\n",
    "# filter all german urls\n",
    "german_urls = []\n",
    "for url in tqdm(content):\n",
    "    parsed_url = urlparse(url)\n",
    "    hostname = parsed_url.hostname\n",
    "    if hostname is None:\n",
    "        continue\n",
    "    if hostname.endswith(\"de\"):\n",
    "        german_urls.append(url)\n",
    "\n",
    "len(german_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4YKNmhBNAz6"
   },
   "outputs": [],
   "source": [
    "download_count = 0\n",
    "\n",
    "for url in tqdm(german_urls):\n",
    "    if url in mappings_pdf:\n",
    "        continue\n",
    "\n",
    "    decoded_str = urllib.parse.unquote(url)\n",
    "    parsed_url = urlparse(decoded_str)\n",
    "    file_name = parsed_url.hostname + \"_\" + os.path.basename(parsed_url.path)\n",
    "    if not file_name.endswith(\".pdf\"):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        with open(os.path.join(PDF_PATH, file_name), \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "            mappings_pdf[url] = file_name\n",
    "\n",
    "        download_count += 1\n",
    "\n",
    "        # Dump mapping to JSON file every 200 downloads\n",
    "        if download_count % 200 == 0:\n",
    "            with open(os.path.join(PDF_PATH, \"mapping.json\"), \"w\") as json_file:\n",
    "                json.dump(mappings_pdf, json_file)\n",
    "\n",
    "# Final dump of mapping to JSON file\n",
    "with open(os.path.join(PDF_PATH, \"mapping.json\"), \"w\") as json_file:\n",
    "    json.dump(mappings_pdf, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLMnu06HNZGk"
   },
   "source": [
    "# PDFs to Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5A4TRNKDNnVb"
   },
   "outputs": [],
   "source": [
    "for url, file_name in tqdm(mappings_pdf.items()):\n",
    "    if url in mappings_img:\n",
    "        continue\n",
    "    pdf_path = os.path.join(PDF_PATH, file_name)\n",
    "    pdf_path = unicodedata.normalize(\"NFC\", pdf_path)\n",
    "    try:\n",
    "        with tempfile.TemporaryDirectory() as path:\n",
    "            image_data = convert_from_path(\n",
    "                pdf_path, output_folder=path, fmt=\"jpeg\", first_page=1, last_page=1\n",
    "            )[0]\n",
    "            image_data.save(os.path.join(IMAGE_PATH, file_name.replace(\".pdf\", \".jpg\")))\n",
    "            mappings_img[url] = file_name.replace(\".pdf\", \".jpg\")\n",
    "            with open(os.path.join(IMAGE_PATH, \"mapping.json\"), \"w\") as f:\n",
    "                json.dump(mappings_img, f)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcribe Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in tqdm(list(mappings_img.keys())):\n",
    "    file_name = mappings_img[url]\n",
    "\n",
    "    if url in transcripts:\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(IMAGE_PATH, file_name)\n",
    "    try:\n",
    "        transcript = pytesseract.image_to_string(Image.open(file_path))\n",
    "        transcripts[url] = transcript\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    if len(transcripts) % 100 == 0:\n",
    "        with open(os.path.join(DATASET_PATH, \"transcripts.json\"), \"w\") as f:\n",
    "            json.dump(transcripts, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Attribute Infomration from Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are an expert data analyst specializing in document analysis and information extraction.\n",
    "            Your task is to carefully analyze a transcribed text from various types of documents (e.g., emails, letters, invoices, invitations)\n",
    "            and extract all relevant attributes describing human or legal entities (Person, Organization, Institution, etc.) of the document.\n",
    "                \n",
    "            Here are EXAMPLES of attributes you should extract.\n",
    "            This is not an exhaustive list, find more interesting attributes yourself.\n",
    "            The attributes MUST directly describe the entity and must be directly extracted from the text.\n",
    "            - Full Name (if available, separate first name and last name)\n",
    "            - Complete Address (including street, city, state/province, postal code, country)\n",
    "            - Phone Number(s) (specify if it's a landline, mobile, or fax)\n",
    "            - Email Address\n",
    "            - Any relevant identification numbers (e.g., Customer ID, Order Number, Invoice Number, License Key)\n",
    "            - Company or Organization name (if applicable)\n",
    "            - Job Title or Role (if mentioned)\n",
    "            \n",
    "            Remember, accuracy is crucial. If you're unsure about any piece of information, indicate your level of confidence or that the information is ambiguous.\n",
    "            \n",
    "            The main target of this analysis are documents that carry detailed information about entities e.g. invoices, business letters, etc.\n",
    "            Give a score from 1 to 10 how good the document fits the quality criteria, 1 being very bad and 10 being very good.\n",
    "            \n",
    "            Please analyze the following transcribed text and provide your detailed extraction:\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attribute(BaseModel):\n",
    "    key: str\n",
    "    value: str\n",
    "\n",
    "class Entity(BaseModel):\n",
    "    name: str\n",
    "    attributes: List[Attribute]\n",
    "\n",
    "class Extraction(BaseModel):\n",
    "    entities: List[Entity]\n",
    "    score: int\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.program import FunctionCallingProgram\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "attribute_list = {}\n",
    "\n",
    "for url in tqdm(list(transcripts.keys())[11:12]):\n",
    "    transcript = transcripts[url]\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": transcript}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    chatgpt_response = response.choices[0].message.content\n",
    "\n",
    "    prompt_template_str = \"\"\"You are an expert data analyst specializing in document analysis and information extraction.\n",
    "    Your task is to carefully analyze a transcribed text from various types of documents (e.g., emails, letters, invoices, invitations)\n",
    "    and extract all relevant attributes describing both the recipient and the sender of the document.\n",
    "    \"\"\"\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(    \n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt_template_str},\n",
    "            {\"role\": \"user\", \"content\": chatgpt_response}\n",
    "        ],\n",
    "        response_format=Extraction,\n",
    "    )\n",
    "\n",
    "    output = completion.choices[0].message.parsed\n",
    "\n",
    "    attribute_list[url] = output.dict()\n",
    "\n",
    "with open(os.path.join(DATASET_PATH, \"attributes.json\"), \"w\") as f:\n",
    "    json.dump(attribute_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = list(attribute_list.keys())[0]\n",
    "attribute_list[url]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade llama-index-core llama-index-readers-file llama-index-llms-ollama llama-index-embeddings-huggingface llama-index-llms-openai llama-index-embeddings-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "#llm = Ollama(model=\"gemma2:27b\")\n",
    "llm = Ollama(model=\"llama3.1:70b\", request_timeout=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(program)chatgpt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import RootModel, BaseModel\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(FunctionCallingProgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.program import FunctionCallingProgram\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "for url in tqdm(list(transcripts.keys())[2001:2002]):\n",
    "    transcript = transcripts[url]\n",
    "\n",
    "    messages = [ChatMessage(role=\"system\", content=prompt), ChatMessage(role=\"user\", content=transcript)]\n",
    "\n",
    "    response = llm.chat(messages)\n",
    "\n",
    "    #print(response)\n",
    "\n",
    "    prompt_template_str = \"\"\"You are an expert data analyst specializing in document analysis and information extraction.\n",
    "    Your task is to carefully analyze a transcribed text from various types of documents (e.g., emails, letters, invoices, invitations)\n",
    "    and extract all relevant attributes describing both the recipient and the sender of the document.\n",
    "    Here is the transcribed text:\n",
    "    {transcript}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    program = FunctionCallingProgram.from_defaults(\n",
    "        output_cls=Extraction,\n",
    "        prompt_template_str=prompt_template_str,\n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    output = program(transcript=transcript)\n",
    "\n",
    "    print(output)\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MSMxjVALdqL"
   },
   "source": [
    "# Extract Metadata from Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:45:50.589708Z",
     "iopub.status.busy": "2024-09-23T15:45:50.589182Z",
     "iopub.status.idle": "2024-09-23T15:45:50.645988Z",
     "shell.execute_reply": "2024-09-23T15:45:50.645574Z",
     "shell.execute_reply.started": "2024-09-23T15:45:50.589686Z"
    }
   },
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:45:51.076629Z",
     "iopub.status.busy": "2024-09-23T15:45:51.075914Z",
     "iopub.status.idle": "2024-09-23T15:45:51.079526Z",
     "shell.execute_reply": "2024-09-23T15:45:51.079093Z",
     "shell.execute_reply.started": "2024-09-23T15:45:51.076604Z"
    },
    "id": "v7QIxRbzgUwk"
   },
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:45:51.739875Z",
     "iopub.status.busy": "2024-09-23T15:45:51.739288Z",
     "iopub.status.idle": "2024-09-23T15:45:51.832695Z",
     "shell.execute_reply": "2024-09-23T15:45:51.832284Z",
     "shell.execute_reply.started": "2024-09-23T15:45:51.739853Z"
    },
    "id": "hINcLALIdtsZ"
   },
   "outputs": [],
   "source": [
    "class BaseEntity(BaseModel):\n",
    "    type: str\n",
    "    email: Optional[List[str]]\n",
    "    phone: Optional[List[str]]\n",
    "    fax: Optional[List[str]]\n",
    "    address: Optional[str]\n",
    "    website: Optional[str]\n",
    "\n",
    "\n",
    "class Person(BaseEntity):\n",
    "    type: Literal[\"person\"]\n",
    "    first_name: str\n",
    "    last_name: Optional[str]\n",
    "    role: Optional[str]\n",
    "    mobile: Optional[List[str]]\n",
    "\n",
    "\n",
    "class Government(BaseEntity):\n",
    "    type: Literal[\"government\"]\n",
    "    department: str\n",
    "    state: Optional[str]\n",
    "    district: Optional[str]\n",
    "    city: Optional[str]\n",
    "\n",
    "\n",
    "class Company(BaseEntity):\n",
    "    type: Literal[\"company\"]\n",
    "    name: str\n",
    "    sector: Optional[str]\n",
    "\n",
    "\n",
    "class Organisation(BaseEntity):\n",
    "    type: Literal[\"organization\"]\n",
    "    name: str\n",
    "    sector: Optional[str]\n",
    "\n",
    "\n",
    "class Group(BaseEntity):\n",
    "    type: Literal[\"group\"]\n",
    "    name: str\n",
    "\n",
    "\n",
    "Entity = Union[Person, Government, Company, Organisation, Group]\n",
    "\n",
    "\n",
    "class ContentType(str, Enum):\n",
    "    presentation = \"presentation\"\n",
    "    mail = \"mail\"\n",
    "    newsletter = \"newsletter\"\n",
    "    werbung = \"werbung\"\n",
    "    einladung = \"einladung\"\n",
    "    bewerbung = \"bewerbung\"\n",
    "    ankündigung = \"ankündigung\"\n",
    "    rechnung = \"rechnung\"\n",
    "    brief = \"brief\"\n",
    "    ausschreibung = \"ausschreibung\"\n",
    "    nachrichten = \"nachrichten\"\n",
    "    antrag = \"antrag\"\n",
    "    angebot = \"angebot\"\n",
    "    urkunde = \"urkunde\"\n",
    "    sonstiges = \"sonstiges\"\n",
    "\n",
    "\n",
    "class DocumentMetadata(BaseModel):\n",
    "    title: str\n",
    "    date: Optional[str]\n",
    "    content_type: ContentType\n",
    "    has_signature: bool\n",
    "    main_author: Optional[Entity]\n",
    "    other_authors: Optional[List[Entity]]\n",
    "    logo_owners: Optional[List[str]]\n",
    "    recipients: Optional[List[Entity]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "95069845244a4c1bb8128fe354d68e43",
      "15eb260fbe1f4f3987708a96269663c6",
      "9b4836f1b33b473cba2d72b0aa7ab55e",
      "e6316ee3b4f84851a1a7c477d266911c",
      "d3ce130b5c284a2ba2e65c3afc447318",
      "69145d688d2941ba9fae7451c87cc356",
      "2d1702c4ecba45a698d1aec9dace6f34",
      "2d4c153d5e4a4d9cbe708f73d049e709",
      "92bf2afb1a3a414fb0a2b221d3ec81a1",
      "2dbfe004063d4bfb87a9a5efc9852044",
      "f97c9395b20249949dc1634cc454eb1a"
     ]
    },
    "id": "Yhc7B0ASU_DQ",
    "outputId": "a02d73fd-175c-446e-f20e-fc0dccd4aab6"
   },
   "outputs": [],
   "source": [
    "for url in tqdm(list(mappings_img.keys())):\n",
    "\n",
    "    if url in extraction:\n",
    "        continue\n",
    "\n",
    "    file_name = mappings_img[url]\n",
    "\n",
    "    file_path = os.path.join(IMAGE_PATH, file_name)\n",
    "\n",
    "    try:\n",
    "        transcript = pytesseract.image_to_string(Image.open(file_path))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    base64_image = encode_image(file_path)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant. Your task is to extract metadata from documents. Structure your answer as clear as possible and be very precise and detailed in your answer.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"\"\"\n",
    "    Analysiere das folgende Dokument und extrahiere die wichtigsten Metadaten. Beantworte dabei die folgenden Punkte:\n",
    "\n",
    "    0. Beschreibung des Dokuments (Inhalt, Form/Format, Auffälliges/Markantes, )\n",
    "\n",
    "    1. Dokumententyp (wähle aus: Präsentation, E-Mail, Urkunde, Newsletter, Werbung, Einladung, Bewerbung, Ankündigung, Rechnung, Brief, Ausschreibung, Antrag, Sonstiges)\n",
    "\n",
    "    2. Titel des Dokuments\n",
    "\n",
    "    3. Datum des Dokuments\n",
    "\n",
    "    4. Ist ein Logo vorhanden und deutet es auf eine Autorschaft hin?\n",
    "    - Welche Firma / Person / Organisation ist Logoinhaber?\n",
    "\n",
    "    5. Ist eine Unterschrift vorhanden, wenn ja von wem?\n",
    "\n",
    "    6. Welche Entitäten (Person, Organisation, Behörde, ...) werden im Dokument genannt? In welchem Kontext werden sie genannt? Welche Rolle nehmen die Entitäten ein?\n",
    "\n",
    "    7. Welche Entitäten könnten Autoren des Dokuments sein und warum? Welche dieser Entitäten werden explizit genannt?\n",
    "\n",
    "    8. Welche Entitäten könnten Empfänger / Zielgruppe des Dokuments sein und warum? Welche dieser Entitäten werden explizit genannt?\n",
    "\n",
    "    9. Liste alle Autoren oder Herausgeber.\n",
    "        - Gib jede Entität (Person, Organisation, Behörde, ...) separat an\n",
    "        - Füge Kontaktinformationen hinzu, falls verfügbar\n",
    "        - Nenne ggf. die Verhältnisse der Entitäten zueinander\n",
    "\n",
    "    10. Liste alle Empfänger.\n",
    "        - Gib jede Entität (Person, Organisation, Behörde, ...) separat an\n",
    "        - Füge Kontaktinformationen hinzu, falls verfügbar\n",
    "        - Nenne ggf. die Verhältnisse der Entitäten zueinander\n",
    "\n",
    "    11. Weitere relevante Metadaten des Dokuments\n",
    "\n",
    "    Hier ist der Mitschrieb des zu analysierenden Dokuments:\n",
    "\n",
    "    {transcript}\n",
    "\n",
    "    Bitte antworte auf Deutsch und strukturiere deine Antwort entsprechend der obigen Punkte.\n",
    "                        \"\"\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"},\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    unstructured_answer = response.choices[0].message.content\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Your task is to correctly format the given information. Integrate as much information as possible!\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"{unstructured_answer} \\n\\n {transcript}\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"},\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        response_format=DocumentMetadata,\n",
    "    )\n",
    "\n",
    "    res = completion.choices[0].message.parsed\n",
    "\n",
    "    res = res.dict()\n",
    "\n",
    "    extraction[url] = {\n",
    "        \"unstructured\": unstructured_answer,\n",
    "        \"transcript\": transcript,\n",
    "        \"metadata\": res,\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(DATASET_PATH, \"extraction.json\"), \"w\", encoding=\"utf8\") as f:\n",
    "        json.dump(extraction, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset from Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "HF_DATASET_PATH = os.path.join(DATASET_PATH, \"hf_dataset\")\n",
    "os.makedirs(HF_DATASET_PATH, exist_ok=True)\n",
    "\n",
    "METADATA_PATH = os.path.join(HF_DATASET_PATH, \"metadata.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (url, data) in tqdm(enumerate(extraction.items())):\n",
    "    file_name = mappings_img[url]\n",
    "    file_path = unicodedata.normalize(\"NFC\", os.path.join(IMAGE_PATH, file_name))\n",
    "\n",
    "    shutil.copyfile(file_path, os.path.join(HF_DATASET_PATH, f\"{i}.jpg\"))\n",
    "\n",
    "    with open(METADATA_PATH, \"a\", encoding=\"utf8\") as f:\n",
    "        data = {\n",
    "            \"file_name\": f\"{i}.jpg\",\n",
    "            \"additional_features\": data[\"metadata\"],\n",
    "        }\n",
    "        f.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from huggingface_hub import login\n",
    "login(token=HF_TOKEN, new_session=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imagefolder\", data_dir=HF_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.push_to_hub(\"sodowo/doc_meta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Donut Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_special_tokens = []  # new tokens which will be added to the tokenizer\n",
    "task_start_token = \"<s>\"  # start of task token\n",
    "eos_token = \"</s>\"  # eos token of tokenizer\n",
    "\n",
    "\n",
    "def json2token(\n",
    "    obj, update_special_tokens_for_json_key: bool = True, sort_json_key: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert an ordered JSON object into a token sequence\n",
    "    \"\"\"\n",
    "    if type(obj) == dict:\n",
    "        if len(obj) == 1 and \"text_sequence\" in obj:\n",
    "            return obj[\"text_sequence\"]\n",
    "        else:\n",
    "            output = \"\"\n",
    "            if sort_json_key:\n",
    "                keys = sorted(obj.keys(), reverse=True)\n",
    "            else:\n",
    "                keys = obj.keys()\n",
    "            for k in keys:\n",
    "                if update_special_tokens_for_json_key:\n",
    "                    (\n",
    "                        new_special_tokens.append(rf\"<s_{k}>\")\n",
    "                        if rf\"<s_{k}>\" not in new_special_tokens\n",
    "                        else None\n",
    "                    )\n",
    "                    (\n",
    "                        new_special_tokens.append(rf\"</s_{k}>\")\n",
    "                        if rf\"</s_{k}>\" not in new_special_tokens\n",
    "                        else None\n",
    "                    )\n",
    "                output += (\n",
    "                    rf\"<s_{k}>\"\n",
    "                    + json2token(\n",
    "                        obj[k], update_special_tokens_for_json_key, sort_json_key\n",
    "                    )\n",
    "                    + rf\"</s_{k}>\"\n",
    "                )\n",
    "            return output\n",
    "    elif type(obj) == list:\n",
    "        return r\"<sep/>\".join(\n",
    "            [\n",
    "                json2token(item, update_special_tokens_for_json_key, sort_json_key)\n",
    "                for item in obj\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        # excluded special tokens for now\n",
    "        obj = str(obj)\n",
    "        if f\"<{obj}/>\" in new_special_tokens:\n",
    "            obj = f\"<{obj}/>\"  # for categorical special tokens\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_metadata(meta):\n",
    "    if meta[\"main_author\"] == None:\n",
    "        return True\n",
    "    if meta[\"recipients\"] == None:\n",
    "        return True\n",
    "    if meta[\"date\"] == None:\n",
    "        return True\n",
    "    if meta[\"logo_owners\"] == None:\n",
    "        return True\n",
    "    if meta[\"other_authors\"] == None:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DonutProcessor\n",
    "import torchvision as tv\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import gc\n",
    "from datasets import Dataset\n",
    "import os\n",
    "import json\n",
    "\n",
    "task_start_token = \"<s>\"\n",
    "eos_token = \"</s>\"\n",
    "processor = DonutProcessor.from_pretrained(\"naver-clova-ix/donut-base\")\n",
    "processor.tokenizer.add_special_tokens(\n",
    "    {\"additional_special_tokens\": [task_start_token, eos_token]}\n",
    ")\n",
    "\n",
    "# Reduce the image size\n",
    "new_size = [1080, 1920]  # Half of the original size\n",
    "processor.feature_extractor.size = new_size\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(new_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create output directory\n",
    "HF_DATASET_PATH_DONUT = os.path.join(DATASET_PATH, \"hf_dataset_donut\")\n",
    "os.makedirs(HF_DATASET_PATH_DONUT, exist_ok=True)\n",
    "\n",
    "dataset_info = []\n",
    "\n",
    "for i, (url, data) in tqdm(enumerate(extraction.items()), total=len(extraction)):\n",
    "    item_path = os.path.join(HF_DATASET_PATH_DONUT, f\"{i}.json\")\n",
    "    #if os.path.exists(item_path):\n",
    "    #    continue\n",
    "\n",
    "    file_name = mappings_img[url]\n",
    "    file_path = unicodedata.normalize(\"NFC\", os.path.join(IMAGE_PATH, file_name))\n",
    "\n",
    "    metadata = data[\"metadata\"]\n",
    "\n",
    "    if filter_metadata(metadata):\n",
    "        continue\n",
    "\n",
    "    metadata = task_start_token + json2token(metadata) + eos_token\n",
    "\n",
    "    input_ids_metadata = (\n",
    "        processor.tokenizer(\n",
    "            metadata,\n",
    "            add_special_tokens=False,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=1000,\n",
    "        )[\"input_ids\"]\n",
    "        .squeeze(0)\n",
    "    )\n",
    "    \n",
    "    metadata_target = input_ids_metadata.clone()\n",
    "    metadata_target[metadata_target == processor.tokenizer.pad_token_id] = -100\n",
    "\n",
    "    # Load and transform the image\n",
    "    image = tv.io.read_image(unicodedata.normalize(\"NFC\", file_path))\n",
    "    image = transforms.ToPILImage()(image)\n",
    "    pixel_values = transform(image)\n",
    "\n",
    "\n",
    "    # TODO: Use tensordict?\n",
    "\n",
    "    with open(item_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"pixel_values\": pixel_values.to(torch.float16).tolist(),\n",
    "            \"metadata\": metadata_target.to(torch.int16).tolist()\n",
    "        }, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "HF_DATASET_PATH_DONUT = os.path.join(DATASET_PATH, \"hf_dataset_donut\")\n",
    "\n",
    "dataset = load_dataset(HF_DATASET_PATH_DONUT)\n",
    "dataset = dataset.with_format(\"torch\")\n",
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#from datasets import Dataset, load_from_disk\n",
    "#from torch.utils.data import DataLoader\n",
    "#data = np.randomdata dddddddddeffe.rand(10_000)\n",
    "#Dataset.from_dict({\"data\": data}).save_to_disk(\"my_dataset\")\n",
    "#ds = load_from_disk(\"my_dataset\").with_format(\"torch\")\n",
    "#dataloader = DataLoader(ds, batch_size=32, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.push_to_hub(\"sodowo/doc_meta_donut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"sodowo/doc_meta_donut\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.with_format(\"torch\")\n",
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZUCVJSAjB3z"
   },
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ptrmsIONa56z",
    "outputId": "1884c0e4-19e2-4a85-e812-7219db7401d9"
   },
   "outputs": [],
   "source": [
    "url = list(extraction.keys())[0]\n",
    "print(\"url:\", url)\n",
    "print(\"\\n\")\n",
    "print(\"EXTRACTION:\")\n",
    "res = extraction[url][\"metadata\"]\n",
    "print(json.dumps(res, indent=4, ensure_ascii=False))\n",
    "from IPython.display import Image\n",
    "\n",
    "file_name = mappings_img[url]\n",
    "file_path = os.path.join(IMAGE_PATH, file_name)\n",
    "Image(filename=file_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "15eb260fbe1f4f3987708a96269663c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69145d688d2941ba9fae7451c87cc356",
      "placeholder": "​",
      "style": "IPY_MODEL_2d1702c4ecba45a698d1aec9dace6f34",
      "value": " 92%"
     }
    },
    "2d1702c4ecba45a698d1aec9dace6f34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d4c153d5e4a4d9cbe708f73d049e709": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2dbfe004063d4bfb87a9a5efc9852044": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69145d688d2941ba9fae7451c87cc356": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92bf2afb1a3a414fb0a2b221d3ec81a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "95069845244a4c1bb8128fe354d68e43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_15eb260fbe1f4f3987708a96269663c6",
       "IPY_MODEL_9b4836f1b33b473cba2d72b0aa7ab55e",
       "IPY_MODEL_e6316ee3b4f84851a1a7c477d266911c"
      ],
      "layout": "IPY_MODEL_d3ce130b5c284a2ba2e65c3afc447318"
     }
    },
    "9b4836f1b33b473cba2d72b0aa7ab55e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d4c153d5e4a4d9cbe708f73d049e709",
      "max": 3000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_92bf2afb1a3a414fb0a2b221d3ec81a1",
      "value": 2774
     }
    },
    "d3ce130b5c284a2ba2e65c3afc447318": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6316ee3b4f84851a1a7c477d266911c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2dbfe004063d4bfb87a9a5efc9852044",
      "placeholder": "​",
      "style": "IPY_MODEL_f97c9395b20249949dc1634cc454eb1a",
      "value": " 2774/3000 [8:57:51&lt;1:15:36, 20.08s/it]"
     }
    },
    "f97c9395b20249949dc1634cc454eb1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
