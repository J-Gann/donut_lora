{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMJdbsg39h0oo1095FOdqI3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/J-Gann/donut_lora/blob/main/DocMeta_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update --yes\n",
        "!apt-get install -y poppler-utils\n",
        "%pip install -q -U transformers\n",
        "%pip install pdf2image\n",
        "%pip install -q gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAltxC6DJVhg",
        "outputId": "0f9c28e6-137f-4c6b-dd11-b6734759f918"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Ign:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,314 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,442 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,591 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,593 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,154 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,191 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,346 kB]\n",
            "Fetched 21.9 MB in 4s (5,083 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.5 [186 kB]\n",
            "Fetched 186 kB in 2s (119 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 123605 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.5_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (10.4.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import VisionEncoderDecoderModel, DonutProcessor\n",
        "from pdf2image import convert_from_path\n",
        "import torchvision as tv\n",
        "import torch\n",
        "\n",
        "task_start_token = \"<s>\"\n",
        "eos_token = \"</s>\"\n",
        "processor = DonutProcessor.from_pretrained(\"naver-clova-ix/donut-base\")\n",
        "processor.tokenizer.add_special_tokens(\n",
        "    {\"additional_special_tokens\": [task_start_token, eos_token]}\n",
        ")\n",
        "\n",
        "processor.feature_extractor.size = [2160, 3840]\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"sodowo/doc_meta\")\n",
        "\n",
        "model.decoder.resize_token_embeddings(len(processor.tokenizer))\n",
        "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
        "model.config.decoder_start_token_id = processor.tokenizer.convert_tokens_to_ids(\n",
        "    [\"<s>\"]\n",
        ")[0]\n",
        "\n",
        "eval_model = model.eval()\n",
        "eval_model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "v7qgUiKwTUnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(file_path):\n",
        "    image_data = convert_from_path(file_path, fmt=\"jpeg\", first_page=1, last_page=1)[0]\n",
        "    image_path = file_path.replace(\".pdf\", \".jpg\")\n",
        "    image_data.save(image_path)\n",
        "    image_data = tv.io.read_image(image_path)\n",
        "    image_data = image_data.permute(1, 2, 0)\n",
        "    pixel_values = processor(image_data, return_tensors=\"pt\").pixel_values\n",
        "    pixel_values = pixel_values.squeeze()\n",
        "    with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
        "        generated_ids = eval_model.generate(pixel_values.unsqueeze(0).to(\"cuda\"))\n",
        "\n",
        "    predicted_label = processor.batch_decode(\n",
        "        generated_ids, skip_special_tokens=True\n",
        "    )[0]\n",
        "\n",
        "    return predicted_label, convert_from_path(file_path, fmt=\"jpeg\", first_page=1, last_page=1)[0]\n",
        "\n",
        "def process_pdf(file):\n",
        "    if file is not None:\n",
        "        return predict(file.name)\n",
        "    return \"No file uploaded.\"\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"### Upload a PDF file for prediction\")\n",
        "    file_input = gr.File(label=\"Choose a PDF file\", file_types=[\".pdf\"])\n",
        "    output = gr.Textbox(label=\"Prediction Result\")\n",
        "    image_output = gr.Image(label=\"Processed Image\")\n",
        "\n",
        "    file_input.change(fn=process_pdf, inputs=file_input, outputs=[output, image_output])\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "511WZGaLPrJv",
        "outputId": "bf27ae52-3fd2-4269-f4b2-f0155cf833b6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://3f8a106aec87278939.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3f8a106aec87278939.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}